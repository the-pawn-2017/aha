[package]
name = "aha"
version = "0.1.8"
edition = "2024"
repository = "https://github.com/jhqxxx/aha"
license = "Apache-2.0"
description = "aha model inference library, now supports Qwen2.5VL, MiniCPM4, VoxCPM, Qwen3VL, DeepSeek-OCR, Hunyuan-OCR, PaddleOCR-VL, VoxCPM1.5, RMBG2.0, GLM-ASR-Nano-2512, Fun-ASR-Nano-2512, Qwen3"

[dependencies]
candle-core = { version = "0.9.1" }
candle-nn = { version = "0.9.1" }
candle-transformers = { version = "0.9.1" }
candle-flash-attn = { version = "0.9.1", optional = true }
serde = "1.0.226"
serde_json = "1.0.145"
anyhow = "1.0.100"
ffmpeg-next = { version = "8.0.0", optional = true }
image = "0.25.8"
reqwest = { version = "0.12.23", features = ["blocking"] }
base64 = "0.22.1"
num = "0.4.3"
minijinja = "2.12.0"
tokenizers = "0.22.1"
aha_openai_dive = { version = "1.4", features = ["stream"] }
uuid = { version = "1.18.1", features = ["v4"] }
chrono = "0.4"
rocket = { version = "0.5.1", features = ["serde_json", "json"] }
tokio = "1.47.1"
hound = "3.5.1"
clap = { version = "4.5.51", features = ["derive"] }
modelscope = "0.1.3"
dirs = "6.0.0"
sysinfo = "0.33"
url = "2.5.7"
rayon = "1.10"
# rubato = "1.0.0"
# audioadapter-buffers = "2.0.0"
realfft = "3.5.0"
symphonia = { version = "0.5.5", features = ["mp3", "wav"] }
serde_yaml = "0.9.34"
zip = "7.2.0"
half = "2.7.1"
byteorder = "1.5.0"

[features]
flash-attn = ["candle-flash-attn"]
cuda = ["candle-nn/cuda", "candle-core/cuda", "candle-transformers/cuda"]
metal = ["candle-nn/metal", "candle-core/metal", "candle-transformers/metal"]
ffmpeg = ["ffmpeg-next"]

[lints.clippy]
needless_range_loop = "allow"
single_range_in_vec_init = "allow"
manual_div_ceil = "allow"
