[package]
name = "aha"
version = "0.1.5"
edition = "2024"
repository = "https://github.com/jhqxxx/aha"
license = "Apache-2.0"
description = "aha model inference library, now supports Qwen2.5VL, MiniCPM4, VoxCPM, Qwen3VL, DeepSeek-OCR, Hunyuan-OCR, PaddleOCR-VL, VoxCPM1.5, RMBG2.0"

[dependencies]
candle-core = { version = "0.9.1"}
candle-nn = { version = "0.9.1"}
candle-transformers = { version = "0.9.1"}
candle-flash-attn = { version = "0.9.1", optional = true }
serde = "1.0.226"
serde_json = "1.0.145"
anyhow = "1.0.100"
ffmpeg-next = { version = "8.0.0", optional = true }
image = "0.25.8"
reqwest = { version = "0.12.23", features = ["blocking"] }
base64 = "0.22.1"
num = "0.4.3"
minijinja = "2.12.0"
tokenizers = "0.22.1"
aha_openai_dive = { git ="https://github.com/jhqxxx/openai-client.git", features = ["stream"]}
uuid = { version = "1.18.1", features = ["v4"]}
chrono = "0.4.42"
rocket = { version = "0.5.1", features = ["serde_json", "json"] }
tokio = "1.47.1"
hound = "3.5.1"
clap = { version = "4.5.51", features = ["derive"] }
modelscope = "0.1.0"
dirs = "6.0.0"
url = "2.5.7"

[features]
flash-attn=["candle-flash-attn"]
cuda=["candle-nn/cuda", "candle-core/cuda", "candle-transformers/cuda"]
ffmpeg=["ffmpeg-next"]

[lints.clippy]
needless_range_loop = "allow"
single_range_in_vec_init = "allow"
